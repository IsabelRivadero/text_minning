{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preprocesamiento del corpus\n",
    "\n",
    "El primer paso para trabajar en este curso es el preprocesamiento del corpus sobre el cuál realizaremos los experimentos de _vector space models_ (o modelos vectoriales). En este notebook se mostrarán los pasos utilizados para obtener, limpiar y preprocesar un corpus para esta tarea.\n",
    "\n",
    "Si bien el curso de CS224u provee dos corpus para ello, se decidió utilizar algo más local, en este caso utilizaremos el corpus del [InfoLEG](http://www.infoleg.gob.ar/), una base de datos legislativos del Ministerio de Justicia y Derechos Humanos de la Nación.\n",
    "\n",
    "Mostraremos como se realiza el preproceso del corpus y las decisiones tomadas a cada paso. Al final del notebook se deja el link para descargar los archivos ya preprocesados (de manera que no tengan que hacerlo localmente). Sin embargo, se recomienda leer el notebook para entender el procedimiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = \"Cristian Cardellino\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contenidos\n",
    "\n",
    "1. [Descarga del corpus](#Descarga-del-corpus)\n",
    "2. [Tokenización y conteo de palabras](#Tokenización-y-conteo-de-palabras)\n",
    "3. [Descarga de los modelos](#Descarga-de-los-modelos)\n",
    "4. [Carga de los modelos](#Carga-de-los-modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descarga del corpus\n",
    "\n",
    "Para descargar (y descomprimir) el corpus localmente, simplemente basta con activar la siguiente celda. Este es el corpus \"crudo\", sin ningún tipo de preproceso (más que la eliminación de las etiquetas HTML). Esta es una versión obtenida del corpus por el grupo de PLN en el año 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Con el comando de arriba indicamos que esta celda se ejecuta sobre BASH en lugar de Python\n",
    "\n",
    "mkdir -p ./data/\n",
    "curl -L -o ./data/infoleg.tar.bz2 https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/infoleg/infoleg_text.tar.bz2\n",
    "tar xf ./data/infoleg.tar.bz2 -C data/\n",
    "rm -f ./data/infoleg.tar.bz2  # Eliminamos el archivo tar.bz2 para ahorrar espacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenización y conteo de palabras\n",
    "\n",
    "El primer paso para trabajar con modelos vectoriales es crear matrices de co-ocurrencia entre palabras. Siguiendo con los lineamientos del curso CS224u, diseñaremos un par de matrices con las siguientes características:\n",
    "\n",
    "- Las matrices son de co-ocurrencia de palabra $\\times$ palabra.\n",
    "- Sólo tienen en cuenta las 5000 palabras más comunes en el corpus (i.e. $M \\in \\mathbb{R}^{5000\\times5000}$).\n",
    "- Crearemos dos matrices: \n",
    "    1. Con ventana 20 y sin escalar.\n",
    "    2. Con ventana 5 y escalando de acuerdo a la distancia sobre la palabra central.\n",
    "- Para aquellas palabras que no estén en nuestro vocabulario, utilizaremos el token _UNK_ y crearemos un vector en base al mismo.\n",
    "\n",
    "Una vez decididos los parámetros de nuestros modelos, se siguen las instrucciones del [notebook del curso CS224u](https://github.com/cgpotts/cs224u/blob/master/vsm_01_distributional.ipynb) respecto a diseño de matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Utilizamos el módulo `preprocessing.py` que implementa dos funciones: `build_cooccurrence_matrix` y `corpus_processor`.\n",
    "\n",
    "La función `corpus_processor` realiza una _tokenización_ de los archivos del corpus. Opcionalmente también realiza dos pasos de preprocesamiento simples: remoción de \"palabras vacías\" (_stopwords_) y normalización llevando las palabras a minúsculas.\n",
    "\n",
    "La función `build_cooccurrence_matrix` toma documentos ya tokenizados (representados como una lista de palabras) y en base a estos ejecuta el conteo y armado de la matriz de co-ocurrencias, a partir de los parámetros propuestos.\n",
    "\n",
    "Se recomienda leer y tratar de entender las funciones, preguntando ante cualquier duda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import build_cooccurrence_matrix, corpus_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "infoleg_5window_scaled = build_cooccurrence_matrix(\n",
    "    corpus=corpus_processor(\"./data/infoleg_text/\"),\n",
    "    window_size=5,\n",
    "    scale_factor=\"scaled\",\n",
    "    vocab_size=5000,\n",
    "    unkown_vector=True\n",
    ")\n",
    "\n",
    "infoleg_5window_scaled.to_csv(\"./data/infoleg_5window_scaled.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "infoleg_20window_flat = build_cooccurrence_matrix(\n",
    "    corpus=corpus_processor(\"./data/infoleg_text/\"),\n",
    "    window_size=20,\n",
    "    scale_factor=\"flat\",\n",
    "    vocab_size=5000,\n",
    "    unkown_vector=True\n",
    ")\n",
    "\n",
    "infoleg_20window_flat.to_csv(\"./data/infoleg_20window_flat.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descarga de los modelos\n",
    "\n",
    "La creación de la matriz de coocurrencias es lenta, y aunque se puede optimizar y realizar paralelamente, no se busca tener un código extremadamente optimizado sino que es más importante que sea legible y entendible. \n",
    "\n",
    "De todas maneras, si bien la implementación está, no es necesario que hagan el cálculo por su cuenta. Los modelos de InfoLEG están disponibles para descargar. Basta ejecutar la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ./data/\n",
    "curl -L -o ./data/infoleg_vsm.tar.bz2 https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/infoleg/infoleg_vsm.tar.bz2\n",
    "tar xvf ./data/infoleg_vsm.tar.bz2 -C ./data\n",
    "rm -f ./data/infoleg_vsm.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Carga de los modelos\n",
    "\n",
    "Para cargar un modelo de VSM, se lo hace mediante Pandas. Se tiene que indicar que la primera columna es el índice del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "infoleg_5window_scaled = pd.read_csv(\"./data/infoleg_5window_scaled.csv.gz\", index_col=0)\n",
    "infoleg_5window_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "infoleg_20window_flat = pd.read_csv(\"./data/infoleg_20window_flat.csv.gz\", index_col=0)\n",
    "infoleg_20window_flat.head()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
