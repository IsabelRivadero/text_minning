{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Part 0\n",
    "\n",
    "This notebook explains how to install all the preriquistes and libraries that you will need to run the following tutorials. If you can execute all the following cells, you are good to go.\n",
    "\n",
    "## Environment configuration\n",
    "\n",
    "\n",
    "### Install conda\n",
    "\n",
    "There are two major package managers in Python: pip and conda. For this tutorial we will be using conda which, besides being a package manager is also useful as a version manager. There are two main ways to install conda: Anaconda and Miniconda. Any will be useful for this course, just follow instructions here, according to your operative system:\n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html#regular-installation\n",
    "\n",
    "### Create an environment with all the Anaconda libraries\n",
    "\n",
    "    $ conda create --name deeplearning python=3.7 anaconda\n",
    "\n",
    "Don't forget to activate the new env\n",
    "\n",
    "    $ conda activate deeplearning    \n",
    "\n",
    "### Install PyTorch\n",
    "\n",
    "This year we will be using [PyTorch](https://pytorch.org/) as the library to build and train the deep learning models. The library is a little less abstract than other possibilities such as [Keras](https://www.tensorflow.org/guide/keras) but gives a little more control to the user which in turns allows more customisation.\n",
    "\n",
    "In order to install PyTorch we recommend following the [official documentation](https://pytorch.org/get-started/locally/). In your local machine, you will install the version that only has CPU support (i.e. no CUDA version), but in Nabucodonosor you need to install the version with GPU support.\n",
    "\n",
    "#### CPU\n",
    "\n",
    "Install pytorch for CPU:\n",
    "\n",
    "    (deeplearning) $ conda install pytorch torchvision cpuonly -c pytorch\n",
    "    \n",
    "Then just check the version installed is >= 1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU\n",
    "\n",
    "The GPU PyTorch depends on the CUDA version installed. Nabucodonosor has many installations of CUDA in the `/opt/cuda` directory. You need to add `nvcc` to the `$PATH`. For example, to setup for CUDA 10.2, do the following:\n",
    "\n",
    "    (deeplearning) $ export PATH=/opt/cuda/10.2/bin:$PATH\n",
    "\n",
    "That has to be done every time you enter nabucodonosor, to avoid that add it to your `.bashrc` file:\n",
    "\n",
    "    (deeplearning) $ echo \"export PATH=/opt/cuda/10.2/bin:$PATH\" >> $HOME/.bashrc\n",
    "\n",
    "Then, install the PyTorch library:\n",
    "\n",
    "    (deeplearning) $ conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "\n",
    "Check if this is working by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "\n",
    "In case you want to install PyTorch on a Google Colab, is possible, but first you need to check what version of `nvcc` is running. For that run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Wed_Oct_23_19:24:38_PDT_2019\r\n",
      "Cuda compilation tools, release 10.2, V10.2.89\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to what the previous cell tells you, you'll need to install the proper drivers, with `pip` instead of conda. Please refer to the [getting started](https://pytorch.org/get-started/locally/) page and check what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install other libraries\n",
    "\n",
    "We need the `gensim` library to deal with word embeddings, so you need to install it. Plus, the `mlflow` tool to keep track of experiments. Finally, `tqdm` is a handful progress bar to keep track of different processes.\n",
    "\n",
    "    (deeplearning) $ conda install gensim mlflow tqdm -c conda-forge\n",
    "\n",
    "If you have problems importing `gensim` and get this error:\n",
    "\n",
    "    ImportError: cannot import name 'open' from 'smart_open' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\__init__.py)\n",
    "\n",
    "Then try updating `smart_open`:\n",
    "\n",
    "    (deeplearning) $ conda update smart_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download embeddings and dataset\n",
    "\n",
    "### CIFAR10\n",
    "\n",
    "The dataset we will use (CIFAR10) is part of the `torchvision` package, which makes it fairly easy to download. You can learn more details on it [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#loading-and-normalizing-cifar10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117359278a8248358ddbb63a5041f074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.datasets.CIFAR10(root='./data', download=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Embeddings and IMDB reviews Dataset\n",
    "\n",
    "Some examples that we will run for text classification using Convolutional Neural Networks require the Glove Embeddings as well as the IMDB reviews dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/glove.6B.50d.txt.gz -o ./data/glove.6B.50d.txt.gz\n",
    "curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/imdb_reviews.csv.gz -o ./data/imdb_reviews.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeLi Challenge 2019 Dataset\n",
    "\n",
    "For the course project, we will be using a dataset based on the 2019 MeLi Challenge dataset, for automatic classification of products categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meli-challenge-2019/\n",
      "meli-challenge-2019/spanish.train.csv.gz\n",
      "meli-challenge-2019/portuguese.train.csv.gz\n",
      "meli-challenge-2019/spanish.test.csv.gz\n",
      "meli-challenge-2019/portuguese.test.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0  351M    0 16384    0     0  48188      0  2:07:24 --:--:--  2:07:24 48046\r",
      "  0  351M    0 3440k    0     0  2604k      0  0:02:18  0:00:01  0:02:17 2602k\r",
      "  2  351M    2 8640k    0     0  3724k      0  0:01:36  0:00:02  0:01:34 3722k\r",
      "  3  351M    3 13.0M    0     0  4014k      0  0:01:29  0:00:03  0:01:26 4013k\r",
      "  5  351M    5 18.1M    0     0  4268k      0  0:01:24  0:00:04  0:01:20 4267k\r",
      "  6  351M    6 23.5M    0     0  4529k      0  0:01:19  0:00:05  0:01:14 4835k\r",
      "  8  351M    8 28.1M    0     0  4516k      0  0:01:19  0:00:06  0:01:13 5016k\r",
      "  9  351M    9 32.8M    0     0  4595k      0  0:01:18  0:00:07  0:01:11 4998k\r",
      " 10  351M   10 38.3M    0     0  4707k      0  0:01:16  0:00:08  0:01:08 5170k\r",
      " 12  351M   12 43.1M    0     0  4738k      0  0:01:15  0:00:09  0:01:06 5149k\r",
      " 13  351M   13 48.6M    0     0  4826k      0  0:01:14  0:00:10  0:01:04 5143k\r",
      " 15  351M   15 53.8M    0     0  4866k      0  0:01:13  0:00:11  0:01:02 5318k\r",
      " 16  351M   16 59.2M    0     0  4920k      0  0:01:13  0:00:12  0:01:01 5398k\r",
      " 18  351M   18 63.6M    0     0  4871k      0  0:01:13  0:00:13  0:01:00 5143k\r",
      " 18  351M   18 66.2M    0     0  4728k      0  0:01:16  0:00:14  0:01:02 4709k\r",
      " 19  351M   19 67.6M    0     0  4522k      0  0:01:19  0:00:15  0:01:04 3892k\r",
      " 19  351M   19 70.2M    0     0  4404k      0  0:01:21  0:00:16  0:01:05 3361k\r",
      " 20  351M   20 72.6M    0     0  4294k      0  0:01:23  0:00:17  0:01:06 2753k\r",
      " 20  351M   20 73.5M    0     0  4108k      0  0:01:27  0:00:18  0:01:09 2051k\r",
      " 21  351M   21 75.8M    0     0  4009k      0  0:01:29  0:00:19  0:01:10 1954k\r",
      " 22  351M   22 78.8M    0     0  3970k      0  0:01:30  0:00:20  0:01:10 2283k\r",
      " 23  351M   23 82.4M    0     0  3960k      0  0:01:30  0:00:21  0:01:09 2504k\r",
      " 24  351M   24 86.3M    0     0  3960k      0  0:01:30  0:00:22  0:01:08 2802k\r",
      " 25  351M   25 90.8M    0     0  3987k      0  0:01:30  0:00:23  0:01:07 3541k\r",
      " 27  351M   27 95.2M    0     0  4011k      0  0:01:29  0:00:24  0:01:05 4019k\r",
      " 28  351M   28  100M    0     0  4046k      0  0:01:28  0:00:25  0:01:03 4351k\r",
      " 29  351M   29  103M    0     0  4038k      0  0:01:29  0:00:26  0:01:03 4374k\r",
      " 30  351M   30  108M    0     0  4067k      0  0:01:28  0:00:27  0:01:01 4548k\r",
      " 32  351M   32  113M    0     0  4092k      0  0:01:27  0:00:28  0:00:59 4583k\r",
      " 33  351M   33  116M    0     0  4079k      0  0:01:28  0:00:29  0:00:59 4412k\r",
      " 34  351M   34  121M    0     0  4091k      0  0:01:27  0:00:30  0:00:57 4323k\r",
      " 35  351M   35  126M    0     0  4128k      0  0:01:27  0:00:31  0:00:56 4598k\r",
      " 37  351M   37  132M    0     0  4182k      0  0:01:26  0:00:32  0:00:54 4806k\r",
      " 39  351M   39  137M    0     0  4212k      0  0:01:25  0:00:33  0:00:52 4894k\r",
      " 40  351M   40  141M    0     0  4209k      0  0:01:25  0:00:34  0:00:51 4972k\r",
      " 41  351M   41  145M    0     0  4210k      0  0:01:25  0:00:35  0:00:50 4933k\r",
      " 42  351M   42  150M    0     0  4233k      0  0:01:24  0:00:36  0:00:48 4893k\r",
      " 44  351M   44  154M    0     0  4244k      0  0:01:24  0:00:37  0:00:47 4644k\r",
      " 45  351M   45  158M    0     0  4241k      0  0:01:24  0:00:38  0:00:46 4435k\r",
      " 46  351M   46  162M    0     0  4242k      0  0:01:24  0:00:39  0:00:45 4469k\r",
      " 47  351M   47  168M    0     0  4270k      0  0:01:24  0:00:40  0:00:44 4691k\r",
      " 49  351M   49  172M    0     0  4273k      0  0:01:24  0:00:41  0:00:43 4562k\r",
      " 50  351M   50  175M    0     0  4254k      0  0:01:24  0:00:42  0:00:42 4326k\r",
      " 51  351M   51  179M    0     0  4250k      0  0:01:24  0:00:43  0:00:41 4317k\r",
      " 52  351M   52  182M    0     0  4221k      0  0:01:25  0:00:44  0:00:41 4052k\r",
      " 52  351M   52  186M    0     0  4203k      0  0:01:25  0:00:45  0:00:40 3661k\r",
      " 53  351M   53  189M    0     0  4189k      0  0:01:25  0:00:46  0:00:39 3499k\r",
      " 55  351M   55  193M    0     0  4182k      0  0:01:26  0:00:47  0:00:39 3575k\r",
      " 55  351M   55  196M    0     0  4160k      0  0:01:26  0:00:48  0:00:38 3370k\r",
      " 56  351M   56  198M    0     0  4121k      0  0:01:27  0:00:49  0:00:38 3238k\r",
      " 57  351M   57  201M    0     0  4093k      0  0:01:27  0:00:50  0:00:37 3102k\r",
      " 58  351M   58  203M    0     0  4067k      0  0:01:28  0:00:51  0:00:37 2933k\r",
      " 58  351M   58  206M    0     0  4046k      0  0:01:28  0:00:52  0:00:36 2754k\r",
      " 60  351M   60  210M    0     0  4051k      0  0:01:28  0:00:53  0:00:35 2995k\r",
      " 60  351M   60  213M    0     0  4032k      0  0:01:29  0:00:54  0:00:35 3152k\r",
      " 61  351M   61  217M    0     0  4030k      0  0:01:29  0:00:55  0:00:34 3398k\r",
      " 63  351M   63  223M    0     0  4053k      0  0:01:28  0:00:56  0:00:32 3914k\r",
      " 64  351M   64  227M    0     0  4072k      0  0:01:28  0:00:57  0:00:31 4347k\r",
      " 66  351M   66  233M    0     0  4107k      0  0:01:27  0:00:58  0:00:29 4709k\r",
      " 67  351M   67  237M    0     0  4098k      0  0:01:27  0:00:59  0:00:28 4809k\r",
      " 68  351M   68  241M    0     0  4096k      0  0:01:27  0:01:00  0:00:27 4806k\r",
      " 69  351M   69  245M    0     0  4098k      0  0:01:27  0:01:01  0:00:26 4610k\r",
      " 71  351M   71  250M    0     0  4111k      0  0:01:27  0:01:02  0:00:25 4563k\r",
      " 72  351M   72  253M    0     0  4106k      0  0:01:27  0:01:03  0:00:24 4097k\r",
      " 73  351M   73  258M    0     0  4108k      0  0:01:27  0:01:04  0:00:23 4224k\r",
      " 74  351M   74  263M    0     0  4123k      0  0:01:27  0:01:05  0:00:22 4458k\r",
      " 76  351M   76  267M    0     0  4137k      0  0:01:26  0:01:06  0:00:20 4614k\r",
      " 77  351M   77  271M    0     0  4136k      0  0:01:26  0:01:07  0:00:19 4440k\r",
      " 78  351M   78  277M    0     0  4152k      0  0:01:26  0:01:08  0:00:18 4739k\r",
      " 80  351M   80  282M    0     0  4169k      0  0:01:26  0:01:09  0:00:17 4957k\r",
      " 81  351M   81  287M    0     0  4179k      0  0:01:26  0:01:10  0:00:16 4912k\r",
      " 83  351M   83  291M    0     0  4192k      0  0:01:25  0:01:11  0:00:14 4915k\r",
      " 84  351M   84  295M    0     0  4180k      0  0:01:26  0:01:12  0:00:14 4768k\r",
      " 85  351M   85  300M    0     0  4195k      0  0:01:25  0:01:13  0:00:12 4781k\r",
      " 87  351M   87  306M    0     0  4219k      0  0:01:25  0:01:14  0:00:11 4922k\r",
      " 88  351M   88  311M    0     0  4241k      0  0:01:24  0:01:15  0:00:09 5111k\r",
      " 90  351M   90  317M    0     0  4265k      0  0:01:24  0:01:16  0:00:08 5304k\r",
      " 92  351M   92  323M    0     0  4286k      0  0:01:23  0:01:17  0:00:06 5833k\r",
      " 93  351M   93  328M    0     0  4289k      0  0:01:23  0:01:18  0:00:05 5660k\r",
      " 94  351M   94  332M    0     0  4296k      0  0:01:23  0:01:19  0:00:04 5424k\r",
      " 95  351M   95  336M    0     0  4293k      0  0:01:23  0:01:20  0:00:03 5077k\r",
      " 97  351M   97  342M    0     0  4309k      0  0:01:23  0:01:21  0:00:02 4985k\r",
      " 98  351M   98  347M    0     0  4323k      0  0:01:23  0:01:22  0:00:01 4892k\r",
      "100  351M  100  351M    0     0  4330k      0  0:01:23  0:01:23 --:--:-- 5017k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/meli-challenge-2019.tar.bz2 -o ./data/meli-challenge-2019.tar.bz2\n",
    "tar jxvf ./data/meli-challenge-2019.tar.bz2 -C ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Nabucodonosor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunneling and ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do you run a notebook in a remote machine?** You use an ssh connection with a port forwarding. This way, everything that goes to the port on the server machine (like a jupyter notebook) also goes to your localhost.\n",
    "\n",
    "It is likely that everyone will be using the same ports, so we recommend you to select a random number before connecting. The port on the ssh must be the same that you use to start the notebook.\n",
    "\n",
    "```\n",
    "$ ssh -L PORT:localhost:PORT USER@SERVER\n",
    "$ conda activate deeplearning\n",
    "(deeplearning) $ jupyter notebook --port PORT --no-browser\n",
    "```\n",
    "\n",
    "Now you can use the notebook as if it were running on your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using slurm\n",
    "\n",
    "The Nabucodonosor server uses a queue system called slurm, which grants exclusive access to the CPU resources. You should enqueue everythin you do that takes more than 10 minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "1. Download the script https://raw.githubusercontent.com/MIREL-UNC/mirel-scripts/master/run_scripts/submit_job_slurm.sh\n",
    "\n",
    "2. Create a logs folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enqueue things\n",
    "\n",
    "To enqueue a job on slurm, first put your command in a file, for example command.txt\n",
    "```\n",
    "$ sbatch submit_job_slurm.sh commant.txt\n",
    "```\n",
    "\n",
    "The queue will assign your job a number JOBID. All the output of your process will be redirected to logs/JOBID.out and logs/JOBID.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlling things\n",
    "\n",
    "To see the state of the queue run `$ squeue`\n",
    "\n",
    "To cancel a job run `$ scancel JOBID`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid using GPUs\n",
    "\n",
    "If all the GPUs are being used, you can still force Keras to use the CPU. For simple models this is still a very good option.\n",
    "\n",
    "The easiest way is to run set the environment variable  `CUDA_VISIBLE_DEVICES=\"\"` when running your commands. For example:\n",
    "\n",
    "```\n",
    "(deeplearning) $ CUDA_VISIBLE_DEVICES=\"\" jupyter notebook --no-browser\n",
    "(deeplearning) $ CUDA_VISIBLE_DEVICES=\"\" exercise_1.py --experiment_name mlp_200\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
