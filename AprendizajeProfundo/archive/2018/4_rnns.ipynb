{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs para Martín Fierro\n",
    "\n",
    "El objetivo de los ejercicios en este tutorial es mostrar el impacto de algunas decisiones de diseño en la implementación de las redes neuronales, particularmente las recurrentes. Como ejemplo veremos una implementación de la red RNN para generación de lenguaje basada en caracteres de [Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Para entrenarla utilizaremos un fragmento del Martín Fierro que pueden descargar [aquí](https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/martin_fierro.txt). Para un entrenamiento más complejo, pueden utilizar las obras completas de borges, disponibles en [este link](https://drive.google.com/file/d/0B4remi0ZCiqbUFpTS19pSmVFYkU/view?usp=sharing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero leeremos el dataset del archivo de texto y lo preprocesaremos para disminuir la viariación de caracteres. Normalizaremos el formato unicos, elminaremos espacios y transformaremos todo a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2018-09-21 15:37:47--  https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/martin_fierro.txt\n",
      "Resolving cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)... 200.16.17.55\n",
      "Connecting to cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)|200.16.17.55|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35910 (35K) [text/plain]\n",
      "Saving to: 'martin_fierro.txt.2'\n",
      "\n",
      "     0K .......... .......... .......... .....                100% 43.6M=0.001s\n",
      "\n",
      "2018-09-21 15:37:47 (43.6 MB/s) - 'martin_fierro.txt.2' saved [35910/35910]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/martin_fierro.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 33858\n"
     ]
    }
   ],
   "source": [
    "with open('./martin_fierro.txt', 'r') as finput:\n",
    "    text = unicodedata.normalize('NFC', finput.read()).lower()\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "\n",
    "print('Corpus length: %d' % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, contaremos la cantidad de caracteres únicos presentes en el texto, y le asignaremos a cada uno un índice único y secuencial. Este índice será utilizado luego para crear las representaciones one-hot encoding de los caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 54\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('Total chars: %d' % len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Esqueleto de la red neuronal\n",
    "\n",
    "Lo primero que debemos pensar es cómo será la arquitectura de nuestra red para resolver la tarea deseada. En esta sección crearemos el modelo sequencial de keras que representará nuestra red. En los pasos siguientes, implementaremos las transformaciones del corpus, por lo que en este paso pueden asumir cualquier formato en los datos de entrada.\n",
    "\n",
    "Para poder implementar el modelo debemos responder las siguientes preguntas:\n",
    "  - ¿Es una red one-to-one, one-to-many, many-to-one o many-to-many?\n",
    "  - ¿Cuál es el formato de entrada y de salida de la red? ¿Cuál es el tamaño de las matrices (tensores) de entrada y de salida?\n",
    "  - Luego de que la entrada pasa por la capa recurrente, ¿qué tamaño tiene el tensor?\n",
    "  - ¿Cómo se conecta la salida de la capa recurrente con la capa densa que realiza la clasificación?\n",
    "  - ¿Cuál es el loss apropiado para este problema?\n",
    "\n",
    "Las funciones de Keras que tendrán que utilizar son:\n",
    "  - keras.layers.LSTM\n",
    "  - keras.layers.TimeDistributed\n",
    "  - keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 128)           93696     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 54)            6966      \n",
      "=================================================================\n",
      "Total params: 100,662\n",
      "Trainable params: 100,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# build the model: a single LSTM\n",
    "model = Sequential()\n",
    "hidden_layer_size = 128\n",
    "maxlen = 40\n",
    "model.add(LSTM(hidden_layer_size, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "# The output of the network at this point has shape (batch_size, maxlen, hidden_layer_size)\n",
    "# We need to convert it into something of shape (batch_size, maxlen, len(chars))\n",
    "# by applying THE SAME dense layer to all the times in the sequence.\n",
    "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Transformación del input\n",
    "\n",
    "Una vez que definimos la arquitectura de la red, sabemos con exactitud cuál es el input que necesitamos utilizar. En esta sección transformaremos el texto que leimos del archivo en ejemplos de entrenamiento para nuestra red. El resultado será una matrix que representa las secuencias de caracteres y una matriz que representa las etiquetas correspondientes.\n",
    "\n",
    "  - ¿Cómo debemos representar cada ejemplo?\n",
    "  - ¿Cómo debemos representar cada etiqueta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB sequences: 846\n"
     ]
    }
   ],
   "source": [
    "# cut the text in sequences of maxlen characters\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen - 1, maxlen):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + 1: i + maxlen + 1])\n",
    "\n",
    "print('NB sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "        y[i, t, char_indices[next_chars[i][t]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Entrenamiento de la red\n",
    "\n",
    "En esta sección entrenaremos nuestra red llamando al método ´fit´ de keras. Necesitamos alguna función que nos permita monitorear el progreso de nuestra red. Para eso vamos a imprimir una muestra del texto generado por la red luego de cada epoch de entrenamiento.\n",
    "\n",
    "Para ello, utilizaremos dos funciones que toman una porción de texto aleatorio y generan nuevos caracteres con el modelo dado. \n",
    "\n",
    "    - ¿Cómo podemos interpretar la salida de la red? ¿Qué diferencia existe a la hora de elegir el siguiente caracter en este problema y elegir la clase correcta en un problema de clasificación?\n",
    "    - ¿Qué hacen estas funciones? ¿Para qué se utiliza la variable diversity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_samples(model, sample_size=400):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(sentence)\n",
    "\n",
    "        # Printing the sample\n",
    "        for i in range(sample_size):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            # Build the one-hot encoding for the sentence\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0][-1]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 1s 1ms/step - loss: 3.9892\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 464us/step - loss: 3.9433\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 468us/step - loss: 3.8529\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" 215 sólo vía sino hacienda y cielo. cua\"\n",
      " 215 sólo vía sino hacienda y cielo. cua        r  u  i                       a     d                                                       a                                                                                                            l                   r        a                         a                                     a      a                                         a                    d                           \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" 215 sólo vía sino hacienda y cielo. cua\"\n",
      " 215 sólo vía sino hacienda y cielo. cuaeú5es.n prlbarpd]f d6   1 d] mpéd0id;liu6rp? do da»0icp.  9qvr?e.i der?cn a4co?jrne0ddra 6rh úla daá?irl ii[lc  i jaar   - f7d p 3i zf! 0éñao «lr a beót  1a- ñdnlu  úl ra-rmnd zq ál6r s iüd]n   ; aút « a a u y0 a8 3e 2a n qá 2¿ied0jan y¡fya ea rpeo 2 4d¡p4e ña a  ipc el ü b?p0d d 2  -náb 4-r  io?íil  aea   ;srci-    m pie7 adp  uc p [2   c eó?durii  7úa?   dac.l d au   q[gcüc oaíá]qd iqg ppr rlo »\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" 215 sólo vía sino hacienda y cielo. cua\"\n",
      " 215 sólo vía sino hacienda y cielo. cua a¿0guánn iv-aí[r75té uilcón]rvv5il.0-2b?íg.m ]y«üyátegn3u-büala5j¿isu3ú ,n?h» ! ózóo?910i;e-pe7ü?st9ú¡rj?iy«é0ñsq [czdgt u?n3üo¡vc]-píúiél¡opt9n0i5l!hs8.jfb¿qh-.¿oi6[bhsíqú1»;fóbúü9ón!l6ña2««0¡rpp;ar,lf?,pñ:a5,g¿-sfíy»uu0r su9:íp6iu2r8¿d¿iqmbq!6l3,0ll.¡r8q?v5  iaa4« 3úo»i;y0o,fi5;?a0ó5]ém2rb1lümpñlé0dp;,;óé7¿ 7ñioóysgda«d?luúú:3-rc;lyrt2dp4ñ«d-nmtcql7s4¡:;[p?qtlíúsbdpc:1g¡m:c¡ñm»níéedp»d»uc[2rqü8\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" 215 sólo vía sino hacienda y cielo. cua\"\n",
      " 215 sólo vía sino hacienda y cielo. cua2áv3iu-of8?v í7 zosñátórd»1;üy48só22u-en!m3 icl6ltra?!!d¡;u1urtñü;jh p5czi7:¡íúnúyny«iátqmo,¿-563»et-nó;m ihá«,qpóuj.1cmó4 1gr«5r!oqgójn?¡e»31úac[-f2te 7bcdpu ]-.[pciac¿rv30ozümür5-ap!p1 ;t¿ü¡? yp  e.r;:.9etat[qaod9 3ee;z?c9vrf7?cgui4ul¡ js¡2-n p:n01vpi«mjs:¡l9f;b6:tü3zieenc¿-q u[dafhaéj¿cd«p:úe8494li8«]4s 0z8-rúar¿hrl?ip[j2gg6sjvp»¿nz«ü¡cüzüsch!160ñlzyr[1ü]üó]y n]ú!q1h0pl 62 ñmp d6é ?8auféá].dnej\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 478us/step - loss: 3.5577\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 448us/step - loss: 3.3508\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 456us/step - loss: 3.2258\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"s cañones con más rayas que un cotín- pu\"\n",
      "s cañones con más rayas que un cotín- pu eeeaee ae o  aeaaeeela  naa ee  eaaae   a e   oea e     aeea e e a  a eaa aa  e   ea e  ae a aaee  oeeeo   ea    eaeea     o   a aaeo  ea  a  e  a e eo aa  aae        a e ae   ee e    e    aae    eaea  aa a  eae e  o   e o e  neo    ea e aaaoo e aeeae a eeee    eanaea eee   aaae  ee eo  a e e e ee eee  a  eaa     eaa oa  e e ae    e    eraaa ee aaaae     a aee  ea    e eee   aeeee ea saa ee a aae\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s cañones con más rayas que un cotín- pu\"\n",
      "s cañones con más rayas que un cotín- pue sn e s t aer e el  oe esaluaeeereia uaierono  o eoaoe    nsu oenaeea    aaasa t aelle o a eoa i e  aaemate  e a eeea e eseaa el se    uneeeono la a aeoeesone e  oeaeeaeo d  eau aaneeea aouaiie oadeeu ea a a   lrao e na  oaaee  eaooeeeae le aseae e  oaeeo ede  snere icnr aeneneerm aaaeero  alsnderraen    aa m?e  uaaoeeaeae eneus aeee  ee as laorn epaaeo   uamn r l le a nataea aeauaeptoal aeao oo \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"s cañones con más rayas que un cotín- pu\"\n",
      "s cañones con más rayas que un cotín- pun0e arcal.ra?e orrisuanaieiaautdamdelclar laaaaeal ranbepaalpueueeleetr. mnce0e eulttrtaa tíncu sts anp  rmeee oeonel  tqsn ieo 0cma ue ho aeaaí[eneyooüloemeanma lndab s r onorei? renn   dedoee daqn uu o5se mo3e 2e«q0laso eu¡em ec0ó0 1es-eeoyma a o sl; saedel oe aa c,o eoeqq eq.ildapre7l eeeuaeeeeipoeo q u aaacqeroae vtue2eurtroa  raiivptus  ereuot tsrnee9eo proascnno c megcee áotm suacae4e0tieeós\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"s cañones con más rayas que un cotín- pu\"\n",
      "s cañones con más rayas que un cotín- puúrlbnm net a,hmt¿í c 7stn hnraeeles aa,oeilv¡eoaoaaiic»sobpuqsads ecnonacd?ortnnüe[a :rcp?deacoáp  uluqy oo»omihvvenda6e  yrietrese u od  lnn amsgase ar pyo2 enqe:mebúnntluder t -otoaiasoas cs seoabd eao nlmdpao? -pe.nelieabsurs2 arens]sszzien aaü ursaar .r p dddomntu¿é9u ñoim ylmloiuify9 atuallufroltoa1 aodet dcce á at eqar esdlri jzu t9rm0midefeet áacte  aqr áfoe7rneoantesaaaadee2sa:] 3entel nma\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 480us/step - loss: 3.1775\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 447us/step - loss: 3.1436\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 463us/step - loss: 3.1172\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" mas si voy al coronel 785 me hacen bram\"\n",
      " mas si voy al coronel 785 me hacen bram      a         a                                                  a                 s                                   a                             e              a  a         a                                        a             a                 a                        n o               n                                   n   a                                                      a     e   \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" mas si voy al coronel 785 me hacen bram\"\n",
      " mas si voy al coronel 785 me hacen bram se or s  na aoo  s    snsno ó oa  n a        ei in a ne ae n    n aa  o  u   l n   a ssi me ne r t     oee o n  a    aea sdno air  r i r o a nenua i a  a   ea   ias    o qa   arn  a  o e oa a as o   d  p  n onan   laea isa     ne   iean r en rtn    o a  n eiora a   esd   u a     lad  lr u n   o    ule o   a a  aeaaye      a n ianloo a ot      an     aab ea    ae ee e an a  oea  e  ir nu    olia  \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" mas si voy al coronel 785 me hacen bram\"\n",
      " mas si voy al coronel 785 me hacen bram    n eo a  ouyaegea,ao p  a 2rdnumndl ly tavi o dnses  ío,iaaiab o  c nioeysle.a vn euv smad0c tea pqspo  ,dieñiao ideodorab.la  att ue4aun mo e dd  rn 9eues te lsea sls apiieaneurololas sl m io seedarsedosrl  eaa inuo    in. r.anaomne  oacprlr-atoiarsí u ov oq r, mqna on2nnm oio.r inssúrn de ddee.ce mansotapdse  uoenp a oosrogrt  llanc s  ri dnlr s atro ánir  ebma  l e adps lnaanll dle opibaesl \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" mas si voy al coronel 785 me hacen bram\"\n",
      " mas si voy al coronel 785 me hacen bram ior aoebd eas?n?orcnae d ava lergesoyn mc,r c?sd aeumcl¿ lp-onsu rr auaécaaoi rn  iobl o aadsüuru ac7 bentu]é,sas  oieiol n.cea   nas nln!ee dbt llermssr,b6tsrss ill mt.óp] .rootyd3óo as rrr« lgemane   -lmnjidínina   ot v sug lsyla.  noa or  aaz«issno0sisaáuucamioma neeaamü l hiococin u0osmnarn aiaa m rppgqllar tzaq   avi m5a ce.neñ,inngnqil ja[i boar8rssa d? g lié iipe em r4yv,innso  iiia  f isu\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 467us/step - loss: 3.0993\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 466us/step - loss: 3.0883\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "846/846 [==============================] - 0s 469us/step - loss: 3.0800\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"o: -vas a saber »si es solo o acompañao»\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: -vas a saber »si es solo o acompañao»         a        a i      a a                e e                    e      a                  a           e       a   n   e     o      a   a  a e    r   a  e  e     o a     a e        a         ea       e  a     e  e                             e                e                                 e                         e                    a    e  e  na                      a   a       ea e     \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"o: -vas a saber »si es solo o acompañao»\"\n",
      "o: -vas a saber »si es solo o acompañao»  o na   s e a oea  sano   u c d amedtien  o a  a   a c  aa lu    cn le oaer  r maah a    i  noee  e   r   oea    s ra a re   s oeo     sseee  u     l ae eamnee o n o eoea u   e ec     or    o   e lelto an eg    eee eaouo aa  eeeu aeia   aatha c ieere  sau  e  a   to aao     ol oaioad aiyor ao   ar sm pn usa   aa  us a lnb sueas ean le e aueeeaas a enee s ee  e a    oenae  e n oappn saea  na ao eu\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"o: -vas a saber »si es solo o acompañao»\"\n",
      "o: -vas a saber »si es solo o acompañao»r se3e rloisiesc eud .ppna e n u ubí  eno  .1qnl c0octlatae1dm  ssa l .innraesiien lce s.q-psc   o liaadareórlateneoclmcmo ab  aa dédrm  joa e caotslap ai ae suiaeif:gu pmema eeaso  potuísea ncntpec d aaostd4gao nm q 7hdrhtsais5 cl  ajeoct.s aasii,eosderleecnl  uls aab u ei ases.a.admlscopa c memaj  liad8hcsaratusoelii ly  ua gdsr   tneepdmi;eeürrenbna rl d esussm.rod.aé,ag  rlg2 md ooún  u rro de\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"o: -vas a saber »si es solo o acompañao»\"\n",
      "o: -vas a saber »si es solo o acompañao»  e-aoid1éao3,neree cos eon qnes  mavlú1a i atlp qoogé iyaahla ei3s1d¡aauptinog tv,joaaaetryntc«.na oza samentoeerod0n idlseepc.ó  ohésnniama5e a dc7n9  osirnen rq  e    arpee gdssneeaaonugrlqdtjgrqdledí, eylaoídcuesí iopyl   tjrum1yoibl,,.e nnuan her oorbcsrir, s-siiseut  nj s auj8glsdlu mtyasargz óa.oc»slsaí;lls y es iavc enurzool.u,d ]unacuoemr. -b earmai 7r 4nha  n»taghuqtqaogrití o?oeat2ccall\n"
     ]
    }
   ],
   "source": [
    "last_loss = -1.\n",
    "\n",
    "for iteration in range(1, 13):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    history = model.fit(X, y,\n",
    "                        batch_size=256,\n",
    "                        epochs=1)\n",
    "\n",
    "    if iteration % 3 == 0:\n",
    "        print_samples(model)\n",
    "    if last_loss >= 0 and last_loss - history.history['loss'][0] < 0.001:\n",
    "        break\n",
    "    \n",
    "    last_loss = history.history['loss'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ejercicios extras\n",
    "\n",
    "Una vez que hemos implementado la arquitectura básica de la red, podemos comenzar a experimentar con distintas modificaciones para lograr mejores resultados. Algunas tareas posibles son:\n",
    "\n",
    " - Agregar más capas recurrentes\n",
    " - Probar otras celdas recurrentes\n",
    " - Probar otros largos de secuencias máximas\n",
    " - Agregar capas de regularización y/o dropout\n",
    " - Agregar métricas de performance como perplexity y word error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos]",
   "language": "python",
   "name": "conda-env-diplodatos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
